name: ppo

# PPO hyperparameters
train_every: 32
ppo_epochs: 4
num_minibatches: 16
clip_param: 0.2
entropy_coef: 0.01
gae_lambda: 0.95
gamma: 0.99
max_grad_norm: 0.5
normalize_advantages: true

# Privileged information flags
priv_actor: false
priv_critic: false

actor:
  lr: 0.0003
  lr_scheduler:
  lr_scheduler_kwargs:

  # mlp architecture
  hidden_units: [256, 128, 128]
  layer_norm: true
  
  weight_decay: 0.0
  gain: 0.01

  vision_encoder: MobileNetV3Small  # if applicable
  use_orthogonal: true

critic:
  num_critics: 1
  value_norm:
    class: ValueNorm1
    kwargs:
      beta: 0.995

  lr: 0.0003
  lr_scheduler:
  lr_scheduler_kwargs:

  # mlp architecture
  hidden_units: [256, 128, 128]
  layer_norm: true

  weight_decay: 0.0
  gain: 0.01

  use_huber_loss: true
  huber_delta: 10

  vision_encoder: MobileNetV3Small  # if applicable
  use_feature_normalization: true
  use_orthogonal: true